{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'generate_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f303c40b7e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgenerate_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_multi_sim_and_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msepia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSepiaModelSetup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'generate_data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from generate_data import generate_multi_sim_and_obs\n",
    "\n",
    "from sepia.SepiaModelSetup import setup_model\n",
    "from sepia.SepiaData import SepiaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multivariate-output simple example\n",
    "\n",
    "First, we generate the synthetic data with 50 points for each simulator run and 20 observed points. \n",
    "\n",
    "Why 5 basis vectors and 3 parameters $\\theta_1,\\theta_2,\\theta_3$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42   # random seed\n",
    "m = 100     # number of simulated observations\n",
    "n = 1       # number of observed data\n",
    "sig_n = 0.01 # observation noise SD\n",
    "\n",
    "data_dict = generate_multi_sim_and_obs(m=m, n=n, nt_sim=50, nt_obs=20,\n",
    "                                       n_theta=3, n_basis=5, \n",
    "                                       sig_n=sig_n, seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the SepiaData object which does some basic checking about whether the input data\n",
    "are of the correct shapes, and infers what kind of model you're going to use based on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = SepiaData(t_sim=data_dict['t_sim'], y_sim=data_dict['y_sim'], y_ind_sim=data_dict['y_ind_sim'],\n",
    "                 y_obs=data_dict['y_obs'], y_ind_obs=data_dict['y_ind_obs'])\n",
    "print(data)\n",
    "\n",
    "plt.plot(data.sim_data.y_ind, data.sim_data.y.T)\n",
    "plt.plot(data.obs_data.y_ind, data.obs_data.y.T, 'k.', linewidth=3)\n",
    "plt.title('Synthetic data (obs. in black)')\n",
    "plt.xlabel('y index')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization of data is important for default priors in the model to work well. In this case, the y index is already on $[0,1]$. We standardize the y values as well. The function standardize y does not actually update the y values, rather it updates the mean and std. Is this because we only need to know the sufficient statistics?\n",
    "\n",
    "We also create a PCA basis with 5 components to represent the multivariate output. Is there a way to look at the PCA to decide if 5 is the right number of basis components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.transform_xt()\n",
    "data.standardize_y()\n",
    "data.create_K_basis(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we set up the model object; a lot of precalculation of important model components is done here. We do not set up a basis for D. Is this becuase we are not modeling the discrepency in this example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = setup_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use all the default priors and settings to do MCMC.\n",
    "\n",
    "We first call `model.tune_step_sizes(50, 20)` which uses 50 samples over 20 different step sizes\n",
    "to find one with a good acceptance rate.\n",
    "\n",
    "We then draw 1000 MCMC samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.tune_step_sizes(50, 20)\n",
    "model.do_mcmc(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a basic visualization of the MCMC results: histograms of the MCMC samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract MCMC samples into dictionary with parameter names\n",
    "samples_dict = {p.name: p.mcmc_to_array() for p in model.params.mcmcList}\n",
    "\n",
    "for i, k in enumerate(samples_dict.keys()):\n",
    "    param_shape = samples_dict[k].shape[1]\n",
    "    if param_shape >= 5:\n",
    "        ncol = 5\n",
    "        nrow = int(np.ceil(param_shape / ncol))\n",
    "    else:\n",
    "        ncol = param_shape\n",
    "        nrow = 1\n",
    "    plt.figure(i)\n",
    "    for j in range(param_shape):\n",
    "        plt.subplot(nrow, ncol, j + 1)\n",
    "        #plt.hist(samples_dict[k][:, j])\n",
    "        plt.plot(samples_dict[k][:, j])\n",
    "        plt.xlabel(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters `betaU` and `lamUz` correspond to the Gaussian process lengthscale and marginal variance,\n",
    "while `lamWs`, `lamWOs`, and `lamOs` are nugget and observation noise precisions.\n",
    "\n",
    "Most easy to interpret is `theta`, which is the posterior distribution over the $t$ that generated $y_{obs}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
